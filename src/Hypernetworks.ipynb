{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--device DEVICE]\n",
      "                             [--num_workers NUM_WORKERS]\n",
      "                             [--save_every SAVE_EVERY] [--verbose VERBOSE]\n",
      "                             [--seed SEED] [--iid IID] --alg\n",
      "                             {fedavg,fedprox,moon,scaffold} --dataset\n",
      "                             {smd,smap,psm} --tsadalg\n",
      "                             {gdn,deep_svdd,usad,tran_ad,lstm_ae}\n",
      "                             [--num_clients NUM_CLIENTS]\n",
      "                             [--slide_win SLIDE_WIN]\n",
      "                             [--client_rate CLIENT_RATE] [--beta BETA]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --alg, --dataset, --tsadalg\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\Pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils import spectral_norm\n",
    "import random\n",
    "from algorithms.Transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "class ViTHyper(nn.Module):\n",
    "\n",
    "    def __init__(self, n_nodes, embedding_dim, hidden_dim, dim, client_sample, heads=8, dim_head=16, n_hidden=1, depth=6,\n",
    "                 spec_norm=False):\n",
    "        super(ViTHyper, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.inner_dim = dim_head * heads\n",
    "        self.depth = depth\n",
    "        self.client_sample = client_sample\n",
    "        # embedding layer\n",
    "        self.embeddings = nn.Embedding(num_embeddings=n_nodes, embedding_dim=embedding_dim)\n",
    "\n",
    "        layers = [\n",
    "            spectral_norm(nn.Linear(embedding_dim, hidden_dim)) if spec_norm else nn.Linear(embedding_dim, hidden_dim),\n",
    "        ]\n",
    "        for _ in range(n_hidden):\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(\n",
    "                spectral_norm(nn.Linear(hidden_dim, hidden_dim)) if spec_norm else nn.Linear(hidden_dim, hidden_dim),\n",
    "            )\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        self.to_qkv_value_list=nn.ModuleList([])\n",
    "        for d in range(self.depth):\n",
    "            to_qkv_value = nn.Linear(hidden_dim, self.dim * self.inner_dim)\n",
    "            self.to_qkv_value_list.append(to_qkv_value)\n",
    "\n",
    "\n",
    "    def finetune(self, emd):\n",
    "        features = self.mlp(emd)\n",
    "        weights=OrderedDict()\n",
    "        for d in range(self.depth):\n",
    "            layer_d_qkv_value_hyper = self.to_qkv_value_list[d]\n",
    "            layer_d_qkv_value = layer_d_qkv_value_hyper(features).view(self.inner_dim,self.dim)\n",
    "            weights[\"transformer.layers.\"+str(d)+\".0.fn.to_qkv.weight\"]=layer_d_qkv_value\n",
    "        return weights\n",
    "\n",
    "\n",
    "    def forward(self, idx, test):\n",
    "        weights = 0\n",
    "        emd = self.embeddings(idx)\n",
    "        print(emd.shape)\n",
    "        features = self.mlp(emd)\n",
    "        print(features.shape)\n",
    "        if test == False:\n",
    "            weights = [OrderedDict()  for x in range(self.client_sample)]\n",
    "            for d in range(self.depth):\n",
    "                layer_d_qkv_value_hyper = self.to_qkv_value_list[d]\n",
    "                layer_d_qkv_value = layer_d_qkv_value_hyper(features).view(-1,self.inner_dim,self.dim)\n",
    "                for nn in range(self.client_sample):\n",
    "                    weights[nn][\"transformer.layers.\"+str(d)+\".0.fn.to_qkv.weight\"]=layer_d_qkv_value[nn]\n",
    "        else:\n",
    "            weights=OrderedDict()\n",
    "            for d in range(self.depth):\n",
    "                layer_d_qkv_value_hyper = self.to_qkv_value_list[d]\n",
    "                layer_d_qkv_value = layer_d_qkv_value_hyper(features).view(self.inner_dim,self.dim)\n",
    "                weights[\"transformer.layers.\"+str(d)+\".0.fn.to_qkv.weight\"]=layer_d_qkv_value\n",
    "        return weights\n",
    "\n",
    "class CNNHyper(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_nodes, embedding_dim, in_channels=3, out_dim=10, n_kernels=16, hidden_dim=100,\n",
    "            spec_norm=False, n_hidden=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_dim = out_dim\n",
    "        self.n_kernels = n_kernels\n",
    "        self.embeddings = nn.Embedding(num_embeddings=n_nodes, embedding_dim=embedding_dim)\n",
    "\n",
    "        layers = [\n",
    "            spectral_norm(nn.Linear(embedding_dim, hidden_dim)) if spec_norm else nn.Linear(embedding_dim, hidden_dim),\n",
    "        ]\n",
    "        for _ in range(n_hidden):\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(\n",
    "                spectral_norm(nn.Linear(hidden_dim, hidden_dim)) if spec_norm else nn.Linear(hidden_dim, hidden_dim),\n",
    "            )\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        self.c1_weights = nn.Linear(hidden_dim, self.n_kernels * self.in_channels * 5 * 5)\n",
    "        self.c1_bias = nn.Linear(hidden_dim, self.n_kernels)\n",
    "        self.c2_weights = nn.Linear(hidden_dim, 2 * self.n_kernels * self.n_kernels * 5 * 5)\n",
    "        self.c2_bias = nn.Linear(hidden_dim, 2 * self.n_kernels)\n",
    "        self.l1_weights = nn.Linear(hidden_dim, 120 * 2 * self.n_kernels * 5 * 5)\n",
    "        self.l1_bias = nn.Linear(hidden_dim, 120)\n",
    "        self.l2_weights = nn.Linear(hidden_dim, 84 * 120)\n",
    "        self.l2_bias = nn.Linear(hidden_dim, 84)\n",
    "        self.l3_weights = nn.Linear(hidden_dim, self.out_dim * 84)\n",
    "        self.l3_bias = nn.Linear(hidden_dim, self.out_dim)\n",
    "\n",
    "        if spec_norm:\n",
    "            self.c1_weights = spectral_norm(self.c1_weights)\n",
    "            self.c1_bias = spectral_norm(self.c1_bias)\n",
    "            self.c2_weights = spectral_norm(self.c2_weights)\n",
    "            self.c2_bias = spectral_norm(self.c2_bias)\n",
    "            self.l1_weights = spectral_norm(self.l1_weights)\n",
    "            self.l1_bias = spectral_norm(self.l1_bias)\n",
    "            self.l2_weights = spectral_norm(self.l2_weights)\n",
    "            self.l2_bias = spectral_norm(self.l2_bias)\n",
    "            self.l3_weights = spectral_norm(self.l3_weights)\n",
    "            self.l3_bias = spectral_norm(self.l3_bias)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        emd = self.embeddings(idx)\n",
    "        features = self.mlp(emd)\n",
    "\n",
    "        weights = OrderedDict({\n",
    "            \"conv1.weight\": self.c1_weights(features).view(self.n_kernels, self.in_channels, 5, 5),\n",
    "            \"conv1.bias\": self.c1_bias(features).view(-1),\n",
    "            \"conv2.weight\": self.c2_weights(features).view(2 * self.n_kernels, self.n_kernels, 5, 5),\n",
    "            \"conv2.bias\": self.c2_bias(features).view(-1),\n",
    "            \"fc1.weight\": self.l1_weights(features).view(120, 2 * self.n_kernels * 5 * 5),\n",
    "            \"fc1.bias\": self.l1_bias(features).view(-1),\n",
    "            \"fc2.weight\": self.l2_weights(features).view(84, 120),\n",
    "            \"fc2.bias\": self.l2_bias(features).view(-1),\n",
    "            \"fc3.weight\": self.l3_weights(features).view(self.out_dim, 84),\n",
    "            \"fc3.bias\": self.l3_bias(features).view(-1),\n",
    "        })\n",
    "        return weights\n",
    "\n",
    "class CNNTarget(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_kernels=16, out_dim=10):\n",
    "        super(CNNTarget, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, n_kernels, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(n_kernels, 2 * n_kernels, 5)\n",
    "        self.fc1 = nn.Linear(2 * n_kernels * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.weight \t torch.Size([50, 10])\n",
      "mlp.0.weight \t torch.Size([128, 10])\n",
      "mlp.0.bias \t torch.Size([128])\n",
      "mlp.2.weight \t torch.Size([128, 128])\n",
      "mlp.2.bias \t torch.Size([128])\n",
      "to_qkv_value_list.0.weight \t torch.Size([128, 128])\n",
      "to_qkv_value_list.0.bias \t torch.Size([128])\n",
      "to_qkv_value_list.1.weight \t torch.Size([128, 128])\n",
      "to_qkv_value_list.1.bias \t torch.Size([128])\n",
      "to_qkv_value_list.2.weight \t torch.Size([128, 128])\n",
      "to_qkv_value_list.2.bias \t torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "hnet = ViTHyper(n_nodes=50, embedding_dim=10, hidden_dim=128, dim=1, client_sample=1, depth=3)\n",
    "tran = Transformer(enc_in=33, c_out=33)\n",
    "input = torch.rand((128, 12, 33))\n",
    "output, attns = tran(input)\n",
    "# print(hnet, tran)\n",
    "for param_tensor in hnet.state_dict():\n",
    "    print(param_tensor, \"\\t\", hnet.state_dict()[param_tensor].size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_embedding.value_embedding.tokenConv.weight \t torch.Size([128, 33, 3])\n",
      "enc_embedding.position_embedding.pe \t torch.Size([1, 5000, 128])\n",
      "enc_embedding.temporal_embedding.hour_embed.emb.weight \t torch.Size([24, 128])\n",
      "enc_embedding.temporal_embedding.weekday_embed.emb.weight \t torch.Size([7, 128])\n",
      "enc_embedding.temporal_embedding.day_embed.emb.weight \t torch.Size([32, 128])\n",
      "enc_embedding.temporal_embedding.month_embed.emb.weight \t torch.Size([13, 128])\n",
      "encoder.attn_layers.0.attention.query_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.query_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.attention.key_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.key_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.attention.value_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.value_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.attention.out_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.out_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.conv1.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.0.conv1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.conv2.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.0.conv2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm1.weight \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm2.weight \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.query_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.query_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.key_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.key_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.value_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.value_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.out_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.out_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.conv1.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.1.conv1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.conv2.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.1.conv2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm1.weight \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm2.weight \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.query_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.query_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.key_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.key_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.value_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.value_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.out_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.out_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.conv1.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.2.conv1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.conv2.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.2.conv2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm1.weight \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm2.weight \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm2.bias \t torch.Size([128])\n",
      "encoder.norm.weight \t torch.Size([128])\n",
      "encoder.norm.bias \t torch.Size([128])\n",
      "projection.weight \t torch.Size([33, 128])\n",
      "projection.bias \t torch.Size([33])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in tran.state_dict():\n",
    "    print(param_tensor, \"\\t\", tran.state_dict()[param_tensor].size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": "_IncompatibleKeys(missing_keys=['enc_embedding.value_embedding.tokenConv.weight', 'enc_embedding.position_embedding.pe', 'enc_embedding.temporal_embedding.hour_embed.emb.weight', 'enc_embedding.temporal_embedding.weekday_embed.emb.weight', 'enc_embedding.temporal_embedding.day_embed.emb.weight', 'enc_embedding.temporal_embedding.month_embed.emb.weight', 'encoder.attn_layers.0.attention.query_projection.weight', 'encoder.attn_layers.0.attention.query_projection.bias', 'encoder.attn_layers.0.attention.key_projection.weight', 'encoder.attn_layers.0.attention.key_projection.bias', 'encoder.attn_layers.0.attention.value_projection.weight', 'encoder.attn_layers.0.attention.value_projection.bias', 'encoder.attn_layers.0.attention.out_projection.weight', 'encoder.attn_layers.0.attention.out_projection.bias', 'encoder.attn_layers.0.conv1.weight', 'encoder.attn_layers.0.conv1.bias', 'encoder.attn_layers.0.conv2.weight', 'encoder.attn_layers.0.conv2.bias', 'encoder.attn_layers.0.norm1.weight', 'encoder.attn_layers.0.norm1.bias', 'encoder.attn_layers.0.norm2.weight', 'encoder.attn_layers.0.norm2.bias', 'encoder.attn_layers.1.attention.query_projection.weight', 'encoder.attn_layers.1.attention.query_projection.bias', 'encoder.attn_layers.1.attention.key_projection.weight', 'encoder.attn_layers.1.attention.key_projection.bias', 'encoder.attn_layers.1.attention.value_projection.weight', 'encoder.attn_layers.1.attention.value_projection.bias', 'encoder.attn_layers.1.attention.out_projection.weight', 'encoder.attn_layers.1.attention.out_projection.bias', 'encoder.attn_layers.1.conv1.weight', 'encoder.attn_layers.1.conv1.bias', 'encoder.attn_layers.1.conv2.weight', 'encoder.attn_layers.1.conv2.bias', 'encoder.attn_layers.1.norm1.weight', 'encoder.attn_layers.1.norm1.bias', 'encoder.attn_layers.1.norm2.weight', 'encoder.attn_layers.1.norm2.bias', 'encoder.attn_layers.2.attention.query_projection.weight', 'encoder.attn_layers.2.attention.query_projection.bias', 'encoder.attn_layers.2.attention.key_projection.weight', 'encoder.attn_layers.2.attention.key_projection.bias', 'encoder.attn_layers.2.attention.value_projection.weight', 'encoder.attn_layers.2.attention.value_projection.bias', 'encoder.attn_layers.2.attention.out_projection.weight', 'encoder.attn_layers.2.attention.out_projection.bias', 'encoder.attn_layers.2.conv1.weight', 'encoder.attn_layers.2.conv1.bias', 'encoder.attn_layers.2.conv2.weight', 'encoder.attn_layers.2.conv2.bias', 'encoder.attn_layers.2.norm1.weight', 'encoder.attn_layers.2.norm1.bias', 'encoder.attn_layers.2.norm2.weight', 'encoder.attn_layers.2.norm2.bias', 'encoder.norm.weight', 'encoder.norm.bias', 'projection.weight', 'projection.bias'], unexpected_keys=['transformer.layers.0.0.fn.to_qkv.weight', 'transformer.layers.1.0.fn.to_qkv.weight', 'transformer.layers.2.0.fn.to_qkv.weight'])"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_id = random.choice(range(50))\n",
    "print(node_id)\n",
    "weights = hnet(torch.tensor([node_id], dtype=torch.long),False)\n",
    "# weights['transformer.layers.0.0.fn.to_qkv.weight'].shape\n",
    "tran.load_state_dict(weights[0],strict=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_embedding.value_embedding.tokenConv.weight \t torch.Size([128, 33, 3])\n",
      "enc_embedding.position_embedding.pe \t torch.Size([1, 5000, 128])\n",
      "enc_embedding.temporal_embedding.hour_embed.emb.weight \t torch.Size([24, 128])\n",
      "enc_embedding.temporal_embedding.weekday_embed.emb.weight \t torch.Size([7, 128])\n",
      "enc_embedding.temporal_embedding.day_embed.emb.weight \t torch.Size([32, 128])\n",
      "enc_embedding.temporal_embedding.month_embed.emb.weight \t torch.Size([13, 128])\n",
      "encoder.attn_layers.0.attention.query_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.query_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.attention.key_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.key_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.attention.value_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.value_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.attention.out_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.0.attention.out_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.conv1.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.0.conv1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.conv2.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.0.conv2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm1.weight \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm2.weight \t torch.Size([128])\n",
      "encoder.attn_layers.0.norm2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.query_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.query_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.key_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.key_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.value_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.value_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.attention.out_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.1.attention.out_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.conv1.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.1.conv1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.conv2.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.1.conv2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm1.weight \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm2.weight \t torch.Size([128])\n",
      "encoder.attn_layers.1.norm2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.query_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.query_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.key_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.key_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.value_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.value_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.attention.out_projection.weight \t torch.Size([128, 128])\n",
      "encoder.attn_layers.2.attention.out_projection.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.conv1.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.2.conv1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.conv2.weight \t torch.Size([128, 128, 1])\n",
      "encoder.attn_layers.2.conv2.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm1.weight \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm1.bias \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm2.weight \t torch.Size([128])\n",
      "encoder.attn_layers.2.norm2.bias \t torch.Size([128])\n",
      "encoder.norm.weight \t torch.Size([128])\n",
      "encoder.norm.bias \t torch.Size([128])\n",
      "projection.weight \t torch.Size([33, 128])\n",
      "projection.bias \t torch.Size([33])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in tran.state_dict():\n",
    "    print(param_tensor, \"\\t\", tran.state_dict()[param_tensor].size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "net = CNNTarget()\n",
    "node_id = random.choice(range(50))\n",
    "print(node_id)\n",
    "hnet = CNNHyper(n_nodes = 50, embedding_dim = 32, in_channels=3, out_dim=10, n_kernels=16, hidden_dim=100,\n",
    "        spec_norm=False, n_hidden=1)\n",
    "weights = hnet(torch.tensor([node_id], dtype=torch.long))\n",
    "# weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([16, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([16])\n",
      "conv2.weight \t torch.Size([32, 16, 5, 5])\n",
      "conv2.bias \t torch.Size([32])\n",
      "fc1.weight \t torch.Size([120, 800])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('conv1.weight',\n              tensor([[[[-3.9400e-01, -1.7225e-03, -6.1360e-02,  8.4005e-02, -1.6359e-01],\n                        [-1.3222e-01,  8.2973e-02,  2.8054e-01, -3.3338e-02,  4.8643e-02],\n                        [-1.0127e-01,  1.1312e-01, -7.3606e-02,  2.7939e-01,  1.0244e-01],\n                        [-7.3823e-02,  5.8411e-02, -6.5767e-03, -1.9918e-01,  7.3714e-02],\n                        [ 2.5907e-01, -2.4011e-02,  8.8819e-02,  2.4550e-02, -3.3810e-01]],\n              \n                       [[-2.4813e-01,  3.7920e-02, -1.0023e-01,  7.2113e-02,  1.7809e-01],\n                        [ 1.0871e-01,  1.5067e-02,  5.0313e-02, -3.4471e-01, -3.3261e-02],\n                        [-3.6178e-03, -8.9375e-02, -3.6598e-02, -7.8733e-02, -3.6396e-02],\n                        [ 1.3598e-01,  1.6788e-01,  1.3791e-01, -2.7951e-01,  2.7573e-01],\n                        [ 4.2601e-02, -8.3858e-02, -3.5726e-02,  1.0721e-01, -9.8043e-02]],\n              \n                       [[-1.6286e-01, -3.2934e-02,  1.5563e-01,  5.1283e-02, -4.1678e-03],\n                        [ 1.1162e-01, -1.1318e-01, -1.4985e-01,  3.4178e-01,  2.8739e-01],\n                        [-3.5792e-01, -2.4337e-01, -2.4448e-01,  5.1753e-02, -1.6986e-01],\n                        [ 1.2927e-01,  1.3782e-01,  8.9126e-02,  1.2994e-03,  2.0922e-02],\n                        [-1.3229e-01, -1.3747e-01,  2.4973e-01,  1.0487e-01,  2.2893e-01]]],\n              \n              \n                      [[[ 1.9667e-01, -5.1993e-02, -1.5358e-01, -2.0298e-02, -7.8442e-02],\n                        [ 1.1331e-01, -6.4762e-02,  1.1883e-01, -7.2215e-02,  1.3488e-01],\n                        [ 1.0067e-01, -1.0101e-01,  2.8242e-01,  4.1201e-02,  5.1249e-02],\n                        [-1.3834e-01, -4.1209e-02, -1.0305e-01,  2.5604e-01,  9.1787e-02],\n                        [ 1.4800e-01,  5.7409e-02, -1.1010e-01, -2.2364e-01,  2.2881e-02]],\n              \n                       [[-2.3782e-01,  5.4131e-03, -1.9379e-01,  1.7340e-01,  3.7646e-01],\n                        [ 1.2755e-01, -1.8860e-02, -1.3815e-01, -8.4062e-02, -1.8810e-01],\n                        [ 1.4480e-01,  1.0156e-01, -8.6899e-03,  1.5800e-01, -1.1176e-01],\n                        [ 2.1843e-01, -2.5991e-01, -2.4725e-02, -1.1539e-01, -3.4723e-01],\n                        [ 1.9782e-01, -1.2987e-01, -3.2019e-01,  6.0976e-02,  7.5058e-02]],\n              \n                       [[ 8.4340e-02, -1.3105e-01, -4.0215e-01, -1.4849e-02, -1.9163e-01],\n                        [-1.2864e-02,  3.2753e-01, -1.6537e-01, -2.6995e-01, -1.2972e-02],\n                        [-2.8781e-01,  1.0906e-01, -2.0034e-01,  1.3141e-01,  1.2773e-01],\n                        [-2.5097e-01, -1.5352e-01,  5.7198e-05, -1.4109e-01,  9.6286e-02],\n                        [-9.9390e-02, -1.5162e-01, -6.9353e-03,  9.0638e-02,  7.9486e-02]]],\n              \n              \n                      [[[ 1.8411e-02,  1.1157e-01,  1.2910e-01,  9.5461e-02, -5.6575e-02],\n                        [-6.8489e-02,  3.4348e-02,  3.2708e-01,  9.0118e-03, -5.0114e-02],\n                        [-3.2603e-02, -7.1926e-02,  1.6951e-01, -6.5593e-02, -1.1651e-01],\n                        [ 1.0142e-01, -8.6141e-02, -1.0580e-01,  8.6454e-02, -1.6544e-01],\n                        [-5.6501e-02, -1.8854e-02,  4.1991e-02, -1.6578e-01,  2.3281e-01]],\n              \n                       [[ 1.7368e-01, -4.2103e-02,  3.4800e-02, -1.1512e-01, -4.3958e-02],\n                        [-8.3810e-02, -1.5999e-01,  1.3752e-01,  2.3594e-02, -1.5903e-01],\n                        [-1.0786e-01,  4.0954e-02,  1.4744e-01, -8.0529e-03, -7.3119e-02],\n                        [ 1.3759e-01,  1.3257e-02, -3.2173e-01,  1.2226e-01, -1.5336e-01],\n                        [ 2.1692e-01,  6.6417e-02, -1.8791e-02,  6.0859e-03,  1.9608e-01]],\n              \n                       [[-6.2307e-02, -7.4880e-02,  9.6693e-02,  5.0548e-02, -8.0494e-02],\n                        [ 4.5800e-03,  7.0869e-04, -1.5513e-01, -1.1257e-01, -2.4804e-01],\n                        [ 9.5140e-02, -1.2216e-01,  2.1656e-01,  2.6333e-01,  1.2662e-01],\n                        [-1.3499e-01,  3.3776e-02, -1.6621e-01, -2.2027e-01,  1.4794e-01],\n                        [-7.1540e-02, -1.1139e-02,  1.1392e-01, -1.7143e-01, -2.2592e-01]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 1.4411e-01, -7.3234e-02,  2.7451e-01,  1.4693e-01, -1.4897e-01],\n                        [ 9.5930e-02, -1.0822e-01, -1.3060e-01, -6.9444e-03, -8.3564e-02],\n                        [-3.7312e-02,  1.9839e-01, -3.7860e-01, -2.7804e-02,  2.4418e-01],\n                        [-2.9021e-01,  1.0368e-02, -1.6418e-01, -1.4997e-01, -1.4216e-02],\n                        [ 2.9212e-01, -1.9456e-02, -2.9682e-02,  2.0326e-01, -4.9708e-02]],\n              \n                       [[ 2.8145e-01, -9.0200e-04, -6.1405e-02,  2.1377e-02, -1.3026e-02],\n                        [ 8.1563e-02, -6.0989e-02, -7.7532e-02,  1.1371e-01, -2.4597e-01],\n                        [ 1.1699e-01, -6.4821e-02,  3.8828e-01, -1.2608e-01,  1.6698e-01],\n                        [-2.7799e-01, -9.6589e-02,  1.9119e-01,  2.9793e-01, -1.0389e-01],\n                        [ 1.8120e-02, -2.9280e-01, -6.1286e-02,  1.7061e-01,  1.6325e-01]],\n              \n                       [[ 2.2323e-01,  2.3741e-03, -5.7857e-02, -8.5051e-02,  8.3848e-02],\n                        [-1.0014e-01, -1.1975e-01, -1.1565e-02,  2.5715e-01, -3.0319e-02],\n                        [-2.8438e-02, -1.9835e-01, -2.0238e-01,  2.1955e-01,  1.3254e-02],\n                        [ 5.1586e-02, -1.7304e-02, -1.1816e-01, -4.3177e-01, -2.2723e-02],\n                        [-2.5412e-01, -1.2957e-01,  2.4192e-02,  6.2986e-02, -3.1663e-01]]],\n              \n              \n                      [[[-2.3246e-01,  8.5947e-02,  2.7325e-01,  1.3078e-01,  2.2327e-01],\n                        [ 2.6046e-02,  4.2726e-01, -2.8861e-02,  1.9601e-01, -1.3868e-01],\n                        [ 1.5406e-01, -6.8376e-02,  7.3792e-02,  5.6079e-02,  2.4231e-01],\n                        [ 3.8743e-02,  1.6669e-02,  6.5582e-02, -1.4828e-01, -4.8374e-02],\n                        [ 3.5820e-02, -2.8530e-01,  1.6186e-01, -4.1167e-02,  3.0471e-02]],\n              \n                       [[ 1.2637e-01, -1.2567e-01, -3.0394e-01,  1.2568e-01, -2.0028e-01],\n                        [-1.7927e-02, -1.0885e-03,  1.6481e-01,  1.0675e-01,  3.0465e-01],\n                        [ 1.4949e-01, -1.2469e-01, -4.1705e-02, -9.2680e-02, -4.1549e-03],\n                        [-8.1051e-02, -1.2731e-01,  1.9178e-01,  5.5712e-03,  1.5694e-01],\n                        [ 7.1144e-02, -1.2499e-01,  7.1957e-02,  1.0645e-01,  6.8867e-02]],\n              \n                       [[ 2.1688e-01,  2.4669e-01,  5.4921e-02,  1.8281e-01, -1.0386e-01],\n                        [ 5.5874e-02,  1.2957e-01,  1.2975e-01, -2.9794e-01,  5.8233e-02],\n                        [ 8.3656e-02,  3.0327e-01, -1.4966e-01, -2.0321e-01, -1.9987e-02],\n                        [-1.5004e-01, -1.7265e-01,  1.7247e-01,  5.8302e-02,  1.0350e-01],\n                        [-1.6786e-01, -5.0116e-03,  2.0490e-02, -2.1304e-02,  3.5128e-02]]],\n              \n              \n                      [[[-3.4913e-01, -9.9197e-02,  3.5729e-02, -1.2191e-01,  5.5016e-02],\n                        [ 2.5535e-01,  1.5737e-01,  1.3863e-01, -8.8893e-02,  4.8077e-02],\n                        [-2.8875e-01,  3.3537e-01, -2.7288e-01, -1.8949e-01, -1.6308e-02],\n                        [ 4.0252e-01, -6.2080e-02,  1.4023e-01,  1.8288e-01,  1.6480e-01],\n                        [-9.1325e-02,  1.2753e-01,  1.6245e-01, -9.1530e-04,  2.0153e-03]],\n              \n                       [[-1.1121e-01, -1.2280e-02,  1.0173e-01,  3.3425e-02, -9.3491e-02],\n                        [ 2.0222e-01,  1.0651e-01, -1.7554e-01, -1.8186e-01,  5.2108e-02],\n                        [ 8.5572e-02,  1.2901e-01,  1.1006e-01, -6.0475e-02, -1.0533e-01],\n                        [ 1.0054e-01, -8.9024e-02, -2.6185e-02,  1.8433e-01, -4.2126e-02],\n                        [ 1.7594e-01, -2.3645e-02, -3.1751e-01,  1.7590e-02,  1.1568e-01]],\n              \n                       [[ 1.3297e-02,  5.6266e-02, -3.4724e-01, -5.0913e-02, -1.3286e-01],\n                        [ 2.9458e-01, -8.5075e-02, -1.3324e-01,  1.9471e-02, -4.2831e-02],\n                        [ 3.5527e-01, -2.5822e-01, -1.2754e-01, -6.6626e-02, -1.0040e-02],\n                        [ 3.0587e-02,  2.5563e-01, -3.1437e-02,  2.0560e-01, -2.0779e-01],\n                        [-1.6042e-01, -1.7746e-02, -1.1896e-01,  5.3080e-02, -4.4083e-02]]]],\n                     grad_fn=<ViewBackward0>)),\n             ('conv1.bias',\n              tensor([-0.0435, -0.0671, -0.2526, -0.1642,  0.0118, -0.1135, -0.1478, -0.1333,\n                      -0.0622, -0.2415, -0.0850, -0.0536,  0.0185,  0.0405, -0.1726, -0.0667],\n                     grad_fn=<ViewBackward0>)),\n             ('conv2.weight',\n              tensor([[[[ 2.5467e-01, -4.2512e-02, -6.9489e-02, -9.7304e-02, -5.6113e-02],\n                        [-3.2609e-01,  3.1959e-02,  2.9513e-02, -2.0141e-01, -5.8910e-02],\n                        [ 2.1349e-01,  5.0804e-02, -2.2635e-02,  5.7209e-02, -3.2225e-02],\n                        [-9.1694e-03,  7.1186e-02,  1.9355e-01,  3.3460e-02,  7.9240e-02],\n                        [ 8.6567e-02, -3.8186e-02,  6.4595e-03,  8.6627e-02, -2.6096e-01]],\n              \n                       [[-1.4670e-01, -1.2333e-01,  9.0783e-03, -9.6035e-02,  2.4163e-01],\n                        [-2.3906e-01,  1.0307e-01, -2.9112e-01, -4.0868e-02, -6.2603e-02],\n                        [ 1.4903e-02, -1.6955e-01, -2.5328e-02,  2.2426e-01, -9.8272e-03],\n                        [-1.1344e-03, -1.9276e-01, -5.8667e-02, -3.0623e-01, -1.9527e-01],\n                        [ 2.2260e-01, -5.2671e-02,  2.1624e-01,  2.2784e-01,  1.6184e-03]],\n              \n                       [[-3.0404e-01,  1.1942e-01,  1.1433e-01, -1.0612e-01, -9.3916e-02],\n                        [-1.5958e-01,  4.1920e-03,  7.0848e-02, -1.1602e-01, -1.1154e-02],\n                        [-3.7894e-02,  2.1564e-01, -4.6190e-02,  1.2420e-02, -1.4770e-01],\n                        [ 1.7275e-01,  4.6410e-02, -1.6984e-01, -5.5243e-02, -1.0093e-01],\n                        [ 2.0825e-01,  2.1014e-01,  1.8434e-01,  2.6081e-02, -2.7285e-01]],\n              \n                       ...,\n              \n                       [[-2.4874e-01,  1.9195e-01,  1.4147e-01, -1.3197e-01, -1.8093e-01],\n                        [-6.3121e-02,  2.0196e-03,  2.8456e-02,  1.8181e-01,  2.1844e-01],\n                        [-2.7056e-02, -8.3484e-02,  2.6302e-01,  7.2402e-02,  2.2532e-01],\n                        [-9.1473e-02,  3.6300e-02,  1.8273e-01, -4.6710e-02,  3.0089e-01],\n                        [-1.3364e-02,  4.8194e-01, -7.7283e-02, -1.7376e-01,  4.3219e-01]],\n              \n                       [[-8.6043e-02,  4.2474e-02, -1.9795e-02, -3.1077e-02, -1.0542e-01],\n                        [ 1.2933e-01,  1.5952e-01, -8.9622e-03, -9.4033e-02,  9.5889e-02],\n                        [ 2.0506e-01, -8.5538e-02,  1.5662e-01,  3.4358e-02,  2.8886e-03],\n                        [-2.6347e-01, -9.5488e-02, -2.8146e-01, -2.2339e-01, -1.2619e-02],\n                        [-2.7466e-01,  2.1954e-01,  9.2218e-02,  9.0624e-02, -1.3227e-01]],\n              \n                       [[ 3.7940e-01,  2.9872e-01,  1.5411e-01, -1.1580e-02,  1.5202e-01],\n                        [ 6.3042e-02,  1.2829e-01, -1.3129e-01, -5.3796e-01, -2.3147e-01],\n                        [ 3.4226e-02,  2.0859e-01,  2.1169e-01, -2.3050e-01, -2.3655e-01],\n                        [-6.1933e-02,  2.5434e-02,  3.4409e-01, -1.9364e-01, -1.0126e-01],\n                        [-2.8168e-01, -1.1020e-01, -1.5690e-01, -9.0989e-02,  2.1934e-01]]],\n              \n              \n                      [[[-1.8844e-01,  1.1714e-01,  4.4737e-02, -2.4166e-01, -8.9285e-02],\n                        [-2.1478e-01,  1.8142e-01,  7.4134e-02, -2.6401e-01, -1.7302e-01],\n                        [ 1.3115e-01,  1.2459e-01, -8.8559e-02, -4.7338e-02, -5.6332e-02],\n                        [ 6.5598e-02, -1.1609e-01, -3.6906e-01, -9.6483e-02, -2.0086e-01],\n                        [ 2.5745e-01, -1.8954e-01,  3.9330e-01, -9.7731e-02, -1.6087e-01]],\n              \n                       [[ 2.3892e-01,  2.0467e-02, -5.6798e-02,  2.3750e-01,  6.1925e-02],\n                        [ 2.6811e-01, -1.6209e-01, -4.5618e-01, -1.0719e-01, -5.8579e-02],\n                        [ 4.8419e-02,  5.1075e-02,  4.5212e-02,  1.6424e-01, -6.3984e-02],\n                        [ 1.0220e-02, -1.7964e-01, -6.0316e-02, -3.8252e-02,  9.6155e-02],\n                        [ 2.6679e-01,  4.6276e-02,  1.8514e-01,  9.4225e-02,  4.6589e-02]],\n              \n                       [[-3.7840e-04, -7.6586e-02, -2.4086e-01, -2.5028e-01,  2.7474e-01],\n                        [ 1.2532e-01,  2.0566e-01,  2.1086e-01,  8.0567e-03,  2.3373e-02],\n                        [-1.7577e-01, -4.4228e-02,  2.2478e-02,  9.1879e-02, -1.8161e-01],\n                        [ 2.0271e-01, -1.5299e-01,  1.4831e-01,  1.2902e-01, -7.0602e-02],\n                        [ 3.2187e-02,  2.5223e-01, -2.9483e-01, -1.3189e-01,  8.8503e-02]],\n              \n                       ...,\n              \n                       [[ 1.5894e-01, -1.0246e-01,  3.5839e-02,  1.7098e-01, -7.0415e-02],\n                        [ 8.3625e-02, -4.2828e-02, -7.4883e-02, -2.7048e-02,  2.4737e-01],\n                        [-3.2975e-01,  5.8993e-02,  8.9824e-02, -1.0661e-01, -3.9891e-01],\n                        [-9.4044e-02,  1.8309e-01, -1.4452e-01, -7.1269e-02,  6.3147e-02],\n                        [-1.6017e-01,  6.8930e-02, -1.2695e-01,  1.3844e-01,  2.3198e-01]],\n              \n                       [[-2.0817e-01,  3.3591e-02,  7.0966e-03,  2.3633e-01,  1.7494e-01],\n                        [-7.0251e-02, -5.1693e-02,  3.7749e-02, -1.1078e-01, -1.8410e-02],\n                        [ 1.0945e-02,  2.2178e-02, -2.0837e-01,  1.7404e-02,  2.4288e-01],\n                        [-1.6322e-01, -2.5322e-01,  1.5185e-01,  1.9440e-01, -5.7037e-01],\n                        [-3.3679e-02, -3.6354e-02,  4.1331e-02,  5.4628e-02,  2.5210e-01]],\n              \n                       [[-1.4847e-01,  2.0625e-01, -1.8221e-01,  1.4251e-03,  7.2669e-02],\n                        [ 3.6347e-02, -2.1087e-01, -6.3592e-02, -1.2775e-01, -8.8170e-02],\n                        [-5.2343e-03,  7.4677e-02,  1.6533e-01, -1.1936e-01,  2.4277e-02],\n                        [ 9.3979e-02,  9.2326e-02,  5.0130e-03,  1.1453e-01, -2.6592e-02],\n                        [ 9.6247e-02,  3.0600e-02, -6.7893e-02, -4.6089e-02,  2.8468e-02]]],\n              \n              \n                      [[[ 1.2557e-01, -3.8987e-01, -2.7654e-01, -1.3703e-01,  1.8383e-01],\n                        [ 9.4112e-02, -4.8433e-02,  1.9568e-01, -4.7186e-02, -1.0600e-01],\n                        [-4.8719e-02, -2.4466e-02,  1.3317e-01,  6.1802e-02,  1.5089e-01],\n                        [ 3.1002e-02, -1.6039e-01,  1.0136e-02,  2.3907e-02, -4.2238e-02],\n                        [-8.3425e-02, -1.2306e-01,  2.2412e-01,  1.5671e-01,  1.4394e-01]],\n              \n                       [[ 1.9780e-01,  1.3251e-01, -1.4542e-01,  2.9317e-02, -8.5347e-02],\n                        [ 2.7219e-01,  6.1430e-02, -2.7918e-02,  1.4793e-01,  1.2214e-01],\n                        [ 1.0241e-02, -2.7572e-02,  1.2843e-01,  8.7674e-02, -8.5248e-02],\n                        [-1.2332e-01, -3.4413e-01, -2.3230e-01,  1.3735e-01, -7.8760e-02],\n                        [ 6.8156e-02,  2.3038e-02, -3.2580e-02, -3.1101e-01,  3.2086e-01]],\n              \n                       [[-2.1657e-01,  6.5105e-02, -2.8051e-01, -6.1060e-02, -3.7889e-02],\n                        [ 7.8972e-02, -4.4827e-02, -1.6087e-01,  4.1337e-02, -1.0746e-01],\n                        [-1.4627e-01, -3.0912e-02, -3.5352e-01,  3.2960e-01, -3.2496e-01],\n                        [-5.2355e-02, -1.8608e-01,  2.5597e-01,  9.0392e-02, -8.3836e-02],\n                        [-1.9755e-01, -2.8856e-01, -8.8140e-02,  2.6592e-02,  9.6469e-02]],\n              \n                       ...,\n              \n                       [[-3.4343e-02, -2.1388e-03,  1.7916e-02, -2.3219e-02,  1.5602e-01],\n                        [ 2.6825e-01, -1.8245e-01, -2.0345e-01, -1.5405e-03, -9.5263e-02],\n                        [ 1.7263e-02, -5.3311e-02,  1.6549e-01,  7.5222e-02, -8.4001e-02],\n                        [-6.8142e-03,  9.5059e-02, -1.7364e-01, -1.0513e-01, -2.2793e-01],\n                        [ 1.6215e-01, -1.5634e-01,  2.5097e-02,  1.5422e-01,  6.8932e-02]],\n              \n                       [[-1.7245e-01,  1.6984e-01, -2.9074e-02, -7.1227e-02, -6.2949e-03],\n                        [ 6.9010e-02, -2.1581e-01, -1.7509e-01,  4.7810e-02, -5.4588e-02],\n                        [-1.4458e-01,  1.4027e-01, -3.6255e-01,  4.3980e-02, -1.1414e-01],\n                        [-8.6402e-02, -1.4545e-01, -5.0302e-02, -4.1100e-01, -1.6604e-02],\n                        [-5.1151e-02,  1.2265e-01, -1.5309e-01, -4.1378e-01,  4.2154e-01]],\n              \n                       [[ 5.7304e-02,  1.7330e-01,  1.7162e-01, -2.0656e-01, -1.2730e-01],\n                        [-2.5452e-02,  1.3268e-01,  8.2703e-02,  1.8420e-01,  9.5162e-03],\n                        [ 2.2741e-01,  1.3320e-01, -9.7170e-02, -3.8829e-02,  2.6296e-01],\n                        [ 3.5560e-02,  1.5578e-01,  1.8838e-01, -3.0836e-01,  1.9815e-01],\n                        [ 1.0310e-01,  3.1652e-01,  1.7118e-01, -2.4528e-01,  2.4041e-01]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 6.8317e-02, -1.3654e-01,  2.7217e-01, -6.7928e-02,  1.5273e-01],\n                        [-6.6180e-03, -1.1829e-02, -4.6711e-02,  9.4534e-02,  9.1657e-02],\n                        [ 1.1213e-02,  1.0886e-01, -2.2181e-01,  1.3136e-01,  1.1857e-01],\n                        [-3.4746e-01,  2.9203e-01,  7.3503e-02, -2.7820e-01,  1.3657e-01],\n                        [-7.5383e-03, -4.7849e-01, -1.2900e-01,  3.4840e-02, -2.1907e-02]],\n              \n                       [[ 1.9563e-01, -4.0240e-02, -6.7105e-02, -1.3525e-03, -1.5766e-01],\n                        [-1.5202e-02, -1.3082e-01,  3.3037e-03, -6.1795e-02, -1.9295e-01],\n                        [-2.5409e-02,  2.0616e-02,  6.6659e-02, -9.3867e-02, -9.1434e-02],\n                        [ 1.2736e-01,  1.2275e-01,  1.2266e-01, -4.7870e-02, -1.4108e-01],\n                        [-4.9643e-02, -1.1732e-01, -5.0155e-02, -7.4218e-02,  1.8731e-01]],\n              \n                       [[ 1.9223e-01,  3.0568e-01, -9.3654e-03,  3.1864e-01, -2.9537e-02],\n                        [-4.2834e-02,  6.9253e-02, -1.7761e-01,  3.4205e-01, -1.7513e-01],\n                        [ 2.7784e-01,  1.6693e-01,  4.9032e-02, -1.3805e-02,  2.0731e-01],\n                        [ 7.0168e-02, -2.7938e-02, -5.0154e-02, -1.4553e-01, -4.8858e-01],\n                        [-1.3598e-01, -5.7955e-02,  1.3426e-01, -3.4552e-02,  1.3283e-01]],\n              \n                       ...,\n              \n                       [[ 1.8063e-01, -2.3901e-02,  1.3188e-01,  1.8738e-01,  7.6572e-02],\n                        [-1.9936e-01,  1.6408e-01, -5.5159e-02,  1.6834e-01,  4.2882e-01],\n                        [-1.9742e-01,  2.2738e-01,  1.8750e-01,  1.6950e-01,  8.9883e-03],\n                        [ 3.1855e-01,  1.5909e-01,  3.3804e-01,  1.4446e-02,  2.5148e-01],\n                        [-2.2980e-01, -1.4150e-01, -2.0000e-01, -1.3384e-02, -1.3604e-01]],\n              \n                       [[-1.5443e-01,  9.2044e-02, -5.7418e-02, -1.0535e-01,  2.7553e-01],\n                        [ 1.2207e-01, -3.2352e-03,  3.4368e-01,  1.9661e-01, -1.6763e-01],\n                        [-1.0556e-01, -9.8368e-02, -4.9817e-02,  8.1005e-02, -1.1985e-01],\n                        [ 1.0889e-01, -1.6196e-01,  4.9393e-02, -8.1076e-02, -2.3571e-01],\n                        [-1.2955e-01,  1.7198e-01,  1.8093e-01,  1.5970e-01,  1.1548e-01]],\n              \n                       [[-7.6360e-02, -3.9309e-01,  3.8078e-01,  1.2069e-01,  2.0309e-01],\n                        [ 2.5443e-01, -2.7888e-01, -1.6476e-01, -1.8838e-01,  1.0684e-01],\n                        [ 3.3057e-01, -1.7475e-02, -3.5232e-03,  1.5425e-01, -3.8339e-02],\n                        [ 2.3014e-01, -5.7936e-02, -1.4294e-01, -1.0930e-03, -5.2490e-02],\n                        [-4.4994e-02, -2.0044e-01,  2.6810e-01,  1.0530e-01, -5.7490e-02]]],\n              \n              \n                      [[[-1.7436e-02, -3.5316e-01, -7.7284e-02,  8.2873e-02,  2.5579e-01],\n                        [ 1.3905e-02,  2.2819e-01, -1.0921e-03, -1.5003e-01,  1.8093e-02],\n                        [ 1.4108e-01, -9.2228e-02, -8.3848e-02,  1.7692e-01,  1.9232e-01],\n                        [ 9.3692e-02,  1.1824e-01,  2.5924e-01,  1.9499e-02,  8.0934e-02],\n                        [ 2.9808e-01, -8.6974e-02, -2.6336e-01, -1.2023e-01,  3.5223e-01]],\n              \n                       [[ 6.6425e-02, -9.5466e-02,  1.1584e-01,  1.2889e-01, -1.3577e-01],\n                        [-8.6709e-02, -6.5062e-03,  2.5047e-03,  1.4755e-01,  2.0275e-01],\n                        [-2.2055e-01,  1.5276e-02,  5.3474e-02,  8.6436e-02, -1.4965e-01],\n                        [ 2.0387e-01, -2.6981e-01, -2.2148e-01,  3.0217e-02, -9.4320e-02],\n                        [ 1.3394e-02,  5.0614e-02,  1.7705e-01, -6.7724e-02, -1.8389e-01]],\n              \n                       [[ 5.4652e-02,  2.1420e-01,  1.0351e-01,  4.1766e-01,  1.0486e-01],\n                        [-4.3341e-02, -1.4568e-01, -1.1735e-01, -6.9469e-02, -1.7827e-01],\n                        [ 2.0897e-02,  5.9097e-02, -1.0612e-01, -1.8880e-01, -1.4597e-01],\n                        [-1.8545e-02, -1.9025e-01,  1.4307e-01,  2.8170e-01,  1.0845e-01],\n                        [ 1.8136e-01, -2.0215e-01,  1.5949e-02, -1.1435e-01,  7.2714e-02]],\n              \n                       ...,\n              \n                       [[-3.4215e-02,  1.9220e-02,  1.6518e-01, -3.2293e-02,  8.9513e-02],\n                        [-1.3463e-01, -2.2644e-01, -1.8441e-01, -3.2661e-01, -4.7574e-02],\n                        [ 6.6120e-02, -4.3238e-02, -2.6713e-01, -1.0505e-01,  7.5747e-02],\n                        [ 2.0545e-01, -6.0692e-02, -1.0551e-01, -4.9450e-02,  9.3770e-02],\n                        [-3.2369e-01, -7.0937e-02, -9.2432e-02, -1.1010e-01,  2.2430e-01]],\n              \n                       [[-1.4968e-01, -2.6628e-05,  2.9402e-02,  3.5135e-01, -2.9340e-01],\n                        [-1.4147e-01, -2.2281e-01, -1.0283e-01, -9.6690e-02,  7.3618e-02],\n                        [ 7.5729e-02,  2.9848e-01, -1.0994e-01, -3.5149e-01, -1.7879e-02],\n                        [ 1.9166e-01,  5.0612e-02,  1.6697e-02, -2.1397e-01,  6.9578e-02],\n                        [ 3.5716e-01, -4.5245e-02,  7.1699e-02, -1.4699e-01, -3.4759e-01]],\n              \n                       [[-3.1753e-01,  1.5669e-02,  3.1589e-02,  4.9037e-02, -9.1903e-03],\n                        [-8.2575e-02, -2.1759e-01, -4.0388e-02,  1.5342e-02,  8.1922e-02],\n                        [ 1.8733e-01,  5.6235e-02, -2.5711e-02,  4.4011e-02,  8.2788e-02],\n                        [-2.8147e-01, -8.5686e-02,  1.1952e-01, -7.3014e-02, -1.0616e-01],\n                        [ 3.2505e-01, -6.7915e-02, -1.0241e-01, -5.9101e-02,  1.5855e-01]]],\n              \n              \n                      [[[-2.6625e-01, -6.3030e-02, -1.7769e-01,  7.1051e-02, -8.8469e-02],\n                        [ 2.2489e-01, -1.2747e-01,  7.9620e-02,  1.4190e-01,  1.7792e-01],\n                        [-2.9985e-01, -1.8395e-01,  8.9558e-02,  2.3899e-01,  7.9616e-02],\n                        [ 1.0616e-01, -1.3072e-01,  2.7204e-01, -1.7663e-01, -1.0455e-01],\n                        [ 2.0384e-01,  7.0304e-02,  3.6398e-02,  1.7593e-01, -8.0581e-02]],\n              \n                       [[-1.0083e-01,  9.7597e-02, -9.9301e-03,  1.0688e-01,  9.2779e-02],\n                        [-7.2992e-02, -1.4984e-02, -3.7349e-01, -8.3177e-02, -2.4475e-01],\n                        [-1.2575e-01,  2.1464e-01, -2.5142e-03,  2.3922e-02, -6.9452e-02],\n                        [ 9.7985e-03,  3.4076e-02,  5.8312e-02, -2.1606e-01,  3.2233e-01],\n                        [ 3.9380e-02,  6.2679e-02, -5.8509e-02, -9.8706e-02, -4.5017e-02]],\n              \n                       [[-3.0016e-02,  5.2702e-02,  3.4460e-02,  1.5953e-01,  1.5157e-01],\n                        [-9.6726e-02, -2.1558e-03,  8.8753e-02, -7.2021e-02,  6.4869e-02],\n                        [ 4.0369e-02,  8.5946e-02,  2.6777e-02,  1.9849e-01, -8.2920e-02],\n                        [ 2.1012e-01, -3.6517e-02,  5.0366e-02, -6.3404e-02,  1.0160e-01],\n                        [-2.5914e-01, -1.0735e-01, -1.9492e-01,  1.1199e-01,  3.4011e-02]],\n              \n                       ...,\n              \n                       [[-2.0203e-01,  3.3493e-02,  9.3457e-02,  1.3117e-01,  6.4661e-02],\n                        [ 8.0766e-02, -1.8065e-01,  2.6623e-01,  2.3050e-02,  6.2275e-02],\n                        [ 2.3968e-01,  1.6654e-01,  3.1177e-02, -1.0335e-01,  8.1722e-02],\n                        [ 2.0780e-01,  1.3857e-01,  2.1512e-01, -1.5340e-01,  9.2001e-02],\n                        [ 1.8211e-01,  1.0356e-01,  2.5953e-01, -3.5707e-01, -7.3266e-02]],\n              \n                       [[-2.5352e-01,  7.8180e-02, -1.1135e-01,  3.2348e-01, -3.7735e-02],\n                        [-2.0936e-01, -1.8070e-01,  1.6890e-01, -5.1126e-01, -2.5158e-01],\n                        [-3.8563e-02, -8.9426e-02,  1.5875e-01,  1.7951e-01, -1.0164e-01],\n                        [ 2.2839e-01, -1.5850e-03,  8.7445e-02, -6.9165e-02, -1.6838e-01],\n                        [-6.1306e-02, -5.6753e-02, -5.0599e-03,  2.1753e-02,  5.0706e-02]],\n              \n                       [[-8.8944e-02,  7.7394e-03,  1.2792e-01, -1.0384e-01, -9.8884e-02],\n                        [-3.3267e-01, -1.4854e-01,  1.4340e-01, -3.4835e-03,  2.3534e-01],\n                        [ 3.8300e-02,  2.6067e-02,  5.8073e-02,  1.9348e-01, -1.2396e-01],\n                        [ 3.0775e-02, -1.4419e-01,  1.4492e-01, -1.0420e-01,  9.0599e-02],\n                        [ 1.7546e-02, -1.9418e-01, -2.8528e-02, -1.8576e-02, -8.9405e-02]]]],\n                     grad_fn=<ViewBackward0>)),\n             ('conv2.bias',\n              tensor([-0.0335, -0.1326, -0.0006,  0.1150,  0.1220,  0.0802,  0.2853,  0.0018,\n                      -0.1549,  0.0946,  0.0937, -0.0645,  0.1120,  0.1877,  0.3110,  0.3423,\n                       0.0525,  0.2470,  0.1330,  0.1063,  0.0467, -0.0006,  0.1400, -0.0465,\n                      -0.2414, -0.3246, -0.0740, -0.1310, -0.1680, -0.0837, -0.0903, -0.2762],\n                     grad_fn=<ViewBackward0>)),\n             ('fc1.weight',\n              tensor([[-0.1378, -0.0056, -0.2475,  ..., -0.0073, -0.1145,  0.2108],\n                      [-0.0191, -0.3273,  0.0808,  ..., -0.0309, -0.1676, -0.0263],\n                      [-0.1172,  0.0990,  0.0257,  ..., -0.0604,  0.0893, -0.2127],\n                      ...,\n                      [-0.2468, -0.1087,  0.0427,  ...,  0.1396,  0.0110,  0.0325],\n                      [-0.1339,  0.0640, -0.0738,  ..., -0.0250,  0.1253, -0.0004],\n                      [ 0.0039,  0.0193, -0.0498,  ...,  0.0249, -0.2159, -0.3069]],\n                     grad_fn=<ViewBackward0>)),\n             ('fc1.bias',\n              tensor([-0.0370, -0.1297, -0.0398, -0.2257, -0.0690, -0.0855, -0.3738, -0.0836,\n                       0.0518, -0.2517,  0.0263,  0.1887,  0.1564,  0.3358, -0.0364, -0.1219,\n                       0.0708, -0.2660, -0.3707,  0.0309,  0.1130, -0.1746, -0.1395, -0.0814,\n                      -0.1580, -0.0738,  0.1592, -0.0051, -0.0495, -0.0975, -0.2208,  0.2226,\n                      -0.2568, -0.2051,  0.1244, -0.1402, -0.0881,  0.0995,  0.1870, -0.1068,\n                       0.4111, -0.0521,  0.2569, -0.1281,  0.0790,  0.0684, -0.0547, -0.1307,\n                      -0.3880,  0.2391,  0.1606, -0.0223,  0.0728, -0.0412,  0.1683,  0.0937,\n                       0.2176, -0.2081, -0.1448,  0.0733,  0.1413, -0.0839,  0.0265,  0.0751,\n                      -0.0110, -0.0653, -0.2493,  0.1194,  0.2264, -0.0048, -0.1201,  0.1626,\n                       0.1191,  0.1896, -0.2463,  0.1399,  0.0393, -0.0789, -0.0875, -0.1926,\n                      -0.0646, -0.0306, -0.0268,  0.1644,  0.0472, -0.2227, -0.2486,  0.1970,\n                       0.1259, -0.1150, -0.0493, -0.0313, -0.0029, -0.0140, -0.3181,  0.1145,\n                       0.2740, -0.2026, -0.4065, -0.0673, -0.0028,  0.0275, -0.2308, -0.3515,\n                       0.0393,  0.0131, -0.0713,  0.0570,  0.1609,  0.2697, -0.0399, -0.1802,\n                      -0.0118,  0.3428, -0.0425, -0.1326,  0.1973,  0.0134,  0.0337, -0.0740],\n                     grad_fn=<ViewBackward0>)),\n             ('fc2.weight',\n              tensor([[-0.1581, -0.0698, -0.1863,  ..., -0.0037,  0.2220,  0.0371],\n                      [ 0.1992,  0.2120, -0.1083,  ..., -0.1388,  0.0061, -0.1675],\n                      [-0.1115,  0.0939,  0.1060,  ..., -0.0725,  0.2609,  0.3745],\n                      ...,\n                      [-0.1019,  0.0058, -0.0469,  ...,  0.0962,  0.1378,  0.2010],\n                      [-0.0144,  0.0674,  0.1412,  ...,  0.0925,  0.1026,  0.1429],\n                      [ 0.0625, -0.0923,  0.2482,  ...,  0.2286,  0.3362,  0.1879]],\n                     grad_fn=<ViewBackward0>)),\n             ('fc2.bias',\n              tensor([-2.8699e-01,  6.5358e-02, -2.1435e-02, -4.8069e-02, -1.7107e-01,\n                      -1.2205e-01,  3.0101e-01, -1.5043e-01,  1.1820e-01,  1.1182e-01,\n                      -1.0084e-01, -1.5729e-01, -4.9803e-02, -1.0744e-01, -7.3156e-02,\n                       2.6022e-01,  4.5415e-02,  1.9094e-01,  3.5586e-02, -1.5431e-01,\n                       1.3385e-01,  1.5957e-01,  4.4223e-01, -1.9290e-01, -1.2719e-01,\n                      -7.2045e-02,  9.6187e-02, -2.7259e-01,  5.2954e-02,  4.8811e-02,\n                      -3.3723e-03,  4.3139e-02,  1.1632e-01, -1.9560e-01,  4.9081e-02,\n                      -2.1218e-02,  1.5056e-01, -4.6555e-01,  9.9611e-04, -3.6350e-01,\n                       5.4419e-02,  1.6846e-01,  2.2650e-01, -1.8377e-01,  5.0937e-02,\n                       1.6255e-01,  1.9497e-02,  1.4291e-01,  6.8518e-02,  1.0551e-01,\n                       2.5804e-02,  1.8336e-01, -2.5064e-04, -2.6706e-01,  1.0741e-01,\n                      -9.3779e-02,  1.9964e-01,  2.0277e-01, -6.5361e-03, -1.5059e-01,\n                       9.8524e-02, -5.5884e-02,  4.9772e-02, -1.2449e-01, -9.1139e-03,\n                       1.1899e-01, -3.0831e-02,  1.3401e-01, -2.6719e-01, -1.1480e-01,\n                       1.5846e-01, -2.0983e-01,  2.6708e-02,  1.1846e-01,  7.3486e-02,\n                       2.1184e-01, -1.5867e-01, -1.3895e-01, -3.2392e-01,  9.9279e-02,\n                      -9.9369e-02,  8.2013e-02, -1.7245e-01,  3.9147e-02],\n                     grad_fn=<ViewBackward0>)),\n             ('fc3.weight',\n              tensor([[ 3.6103e-01,  4.1519e-03, -3.0089e-02, -1.9755e-02, -1.7996e-01,\n                        8.8997e-02, -1.5273e-01, -1.6146e-01,  2.1524e-01,  8.2134e-02,\n                        6.7393e-02,  1.7409e-01,  1.1736e-01,  1.3965e-01,  2.2956e-01,\n                        4.4036e-03,  2.6605e-01, -7.3721e-02, -1.8342e-01, -2.2183e-01,\n                       -5.9717e-02,  9.5642e-02, -1.3625e-01,  1.3662e-02, -1.9489e-01,\n                        2.1094e-01,  4.4735e-02,  2.1792e-01, -1.7936e-01,  2.5808e-01,\n                        2.7739e-01, -5.5652e-02,  5.3092e-02, -4.7684e-02,  4.8904e-02,\n                        1.8617e-01, -2.0385e-01,  8.7426e-02, -2.0386e-01,  6.3236e-02,\n                       -5.6690e-02,  6.9813e-02,  9.7467e-02, -1.2486e-01, -2.8834e-01,\n                       -3.3598e-01, -2.8072e-02, -9.0971e-02,  2.3992e-01, -1.8808e-01,\n                        9.9268e-02, -8.1703e-04,  2.3391e-01,  1.2903e-01,  1.0692e-02,\n                        5.8314e-02, -2.1627e-01, -1.7647e-01, -1.4691e-01, -2.5981e-01,\n                        2.5970e-03, -5.3102e-02, -1.2893e-01, -1.2869e-01, -2.8852e-01,\n                       -9.2186e-02, -4.8674e-02,  8.6147e-02,  7.7301e-02,  1.8511e-01,\n                        1.7976e-04,  3.1991e-01,  1.0099e-01,  2.2978e-02,  1.3399e-02,\n                        1.6991e-02,  2.8497e-02, -1.6297e-01, -1.7270e-01, -5.4130e-02,\n                       -7.9213e-02,  4.7956e-03,  2.1584e-01,  9.8467e-04],\n                      [ 5.7993e-02,  3.5237e-02, -8.1005e-02, -1.3675e-01, -2.0688e-01,\n                        3.7590e-02, -4.6849e-02,  5.9048e-02, -1.3135e-01, -1.5318e-01,\n                       -2.5896e-01, -2.4615e-01,  2.1607e-01,  1.0427e-01, -7.3332e-02,\n                       -4.6902e-02, -1.2185e-01, -1.2829e-01, -4.1090e-02,  4.9543e-02,\n                        1.3379e-01,  5.4012e-02,  1.0103e-01, -2.9028e-01,  3.0386e-01,\n                        3.1402e-01, -1.5695e-01, -1.6759e-01, -1.5524e-01, -9.3188e-02,\n                        2.1761e-01, -1.6825e-02,  1.1082e-01, -1.1520e-01,  1.7080e-01,\n                        3.0162e-02,  1.3584e-01,  2.5340e-02,  1.3099e-01,  1.7893e-01,\n                       -4.1724e-03, -7.9272e-02, -1.3972e-01,  2.4018e-02,  4.7747e-02,\n                       -2.6147e-02,  3.9770e-02, -4.5826e-02, -5.7896e-02,  1.3723e-01,\n                       -1.9029e-01,  1.8642e-01, -4.5621e-02,  7.2123e-02, -4.3828e-01,\n                        3.3686e-01, -1.3724e-01, -5.4383e-02,  2.5940e-01,  5.9591e-03,\n                        1.2072e-01, -3.4235e-02,  2.4479e-01, -8.3594e-02, -7.3792e-02,\n                        5.5984e-02,  9.4691e-02, -1.9319e-01,  5.3448e-02,  1.7109e-01,\n                       -3.4220e-01,  6.5210e-02,  1.2908e-01,  3.5113e-01,  4.1081e-01,\n                        2.3405e-01,  6.2026e-02, -6.2191e-02, -8.0811e-02, -4.7456e-02,\n                       -5.5437e-02, -5.2572e-02,  2.5293e-01, -1.7351e-01],\n                      [-2.8237e-01,  1.6716e-01,  3.3587e-02, -2.6505e-02,  1.8207e-01,\n                       -2.2073e-01,  1.1738e-01, -1.2769e-01,  3.6774e-02, -1.0509e-01,\n                       -8.1622e-02, -1.1283e-01,  1.9232e-01,  6.2736e-02, -2.0382e-01,\n                        2.5084e-01,  3.7675e-02,  7.3244e-02,  1.5930e-02,  1.4652e-01,\n                        1.1462e-01,  9.2164e-02,  6.0613e-02,  2.4228e-02, -8.7672e-02,\n                        6.8866e-02, -1.4093e-02,  7.4426e-02, -1.3109e-01, -5.7462e-02,\n                        4.3255e-03, -5.7581e-02, -3.2956e-02,  1.2080e-01,  1.4883e-01,\n                        1.4642e-01,  1.5902e-01,  1.2367e-01, -1.2428e-02,  1.4475e-01,\n                        4.6269e-02,  2.0155e-01, -8.1804e-02,  7.3311e-02,  1.7904e-01,\n                        1.2642e-01, -9.0729e-02,  9.7980e-02, -1.1312e-01,  1.7886e-01,\n                       -4.6522e-02,  2.5424e-02, -2.1935e-01,  7.3384e-02,  2.3692e-01,\n                       -2.9074e-02, -8.7207e-02, -2.9869e-01, -2.3906e-01, -2.5724e-01,\n                        1.2158e-01,  2.3099e-01,  1.0532e-01, -2.0402e-01,  2.6821e-01,\n                        1.0973e-01, -1.0534e-01, -5.3205e-02, -8.7431e-03,  2.5360e-01,\n                       -1.0233e-01, -1.8956e-01, -1.1308e-01,  1.6805e-01,  1.1530e-01,\n                       -9.7566e-02,  1.1500e-01,  1.7396e-01, -7.0391e-02, -1.0164e-01,\n                       -1.0585e-02, -2.9725e-01,  1.3705e-01, -7.0721e-02],\n                      [-3.9901e-02,  1.9718e-01,  1.2988e-01, -2.1707e-01,  7.1697e-02,\n                        1.0307e-02, -4.6240e-02,  1.5322e-01,  5.7365e-02,  9.8706e-02,\n                        1.5074e-01,  6.9065e-02, -2.0236e-01,  1.4998e-01,  1.9633e-01,\n                       -2.6049e-01,  4.6504e-03,  1.5613e-01, -2.3317e-01,  8.7646e-02,\n                       -1.3691e-01, -1.1061e-01, -1.2387e-01, -1.4821e-01, -2.4693e-03,\n                        6.2671e-02, -8.5746e-02, -6.4958e-02, -4.7445e-02, -1.2243e-01,\n                       -1.5091e-01, -6.9921e-02, -4.1188e-02,  3.4251e-01, -1.4956e-01,\n                       -9.5088e-02, -1.1032e-01,  1.5478e-02,  3.9307e-02,  4.6890e-02,\n                        3.1127e-01,  5.6161e-02, -1.9199e-01, -6.2037e-02,  3.2280e-02,\n                       -1.0434e-01,  1.7926e-01,  1.3572e-01, -8.3262e-03,  2.7600e-01,\n                       -2.0008e-01,  4.1584e-01, -1.7989e-01,  4.5344e-02, -3.2676e-01,\n                       -2.8663e-02, -3.3729e-02, -8.2622e-02, -4.4263e-02, -8.5279e-02,\n                       -1.5444e-01,  1.9732e-01, -2.3404e-01, -2.4561e-01,  2.0224e-01,\n                       -1.3253e-01, -1.6846e-01,  2.7714e-01, -3.0933e-02, -1.9422e-01,\n                       -2.4548e-01, -1.8377e-01, -1.8001e-01, -1.8341e-01,  2.8416e-01,\n                        6.4604e-02, -3.1022e-03, -1.4489e-01, -1.4742e-01,  8.2207e-02,\n                       -3.5608e-01,  1.5335e-01, -1.1620e-01,  3.8502e-02],\n                      [-2.2300e-01, -2.1581e-01, -6.7794e-02, -1.6888e-01,  1.0671e-01,\n                       -4.8842e-02, -6.5749e-03, -3.4319e-02, -1.4724e-01,  1.8261e-01,\n                       -1.0675e-01, -1.5223e-01,  3.3979e-01,  1.3581e-01,  1.8873e-01,\n                        2.4336e-01,  1.9455e-01, -2.1549e-02,  1.8147e-01, -4.9260e-02,\n                        2.0465e-01,  3.7477e-01, -4.6022e-02,  3.7987e-01,  2.5689e-01,\n                        2.5990e-01,  2.9535e-02, -5.2604e-03, -3.8662e-02,  2.5625e-01,\n                        4.1118e-02, -3.4137e-02,  2.3610e-01,  2.1247e-01,  3.8635e-04,\n                       -1.0016e-01,  2.4463e-01,  2.6428e-01, -4.6098e-02,  2.2255e-01,\n                       -4.4695e-02, -8.9052e-02,  8.6841e-02, -1.7001e-01,  5.9420e-02,\n                       -4.3121e-02, -1.7279e-01,  2.7757e-01, -4.3796e-03, -2.3421e-02,\n                        2.6440e-01, -1.2005e-01,  2.4168e-01, -2.0436e-01,  3.3197e-02,\n                       -5.7834e-02, -7.5719e-03,  1.9555e-01,  1.3788e-01, -1.0896e-02,\n                       -1.4714e-01, -1.2351e-02,  2.0818e-02, -1.4831e-01, -2.8404e-01,\n                       -1.5004e-01,  1.6763e-01,  8.3591e-02, -2.3181e-01, -1.5798e-01,\n                       -5.3416e-02, -1.1472e-01,  2.0055e-01, -1.9033e-01, -1.3381e-01,\n                        3.6476e-02,  1.4521e-02, -2.0873e-01,  2.9475e-01,  2.9865e-01,\n                       -2.8351e-02, -1.0182e-01, -3.0347e-01, -9.7095e-03],\n                      [-3.6049e-02, -1.1135e-01,  1.1898e-01, -3.1136e-01, -1.1394e-01,\n                        2.1288e-01, -2.3051e-01, -1.6048e-01,  3.6677e-03, -2.8472e-02,\n                        2.2705e-02, -3.0051e-02, -4.7754e-02, -2.9447e-01, -1.6199e-01,\n                       -5.0701e-02,  6.3246e-02, -4.3739e-01, -5.2371e-01, -3.2474e-02,\n                       -1.2554e-02, -2.8510e-01, -2.4003e-03, -3.7102e-01,  1.5362e-01,\n                        2.6630e-01,  7.4945e-02,  4.1391e-01, -9.3617e-03,  2.1637e-03,\n                       -1.1277e-01,  1.5811e-01,  6.5619e-02, -5.1391e-02, -3.3779e-01,\n                        1.0330e-01,  1.8929e-01, -9.9262e-02,  1.3332e-01,  3.7801e-02,\n                       -7.6118e-03,  1.8243e-01,  3.1221e-02, -1.8405e-01,  1.1321e-01,\n                       -2.1067e-02, -8.6178e-02,  5.0421e-02,  7.9304e-02, -1.2357e-01,\n                       -7.4722e-03,  5.6272e-01, -6.3504e-02, -2.3074e-01, -9.0476e-02,\n                        5.4471e-02, -2.1791e-01,  3.1147e-02, -2.7948e-01,  6.0685e-02,\n                       -3.3490e-01, -1.5687e-01,  2.7636e-01, -3.1428e-02, -4.9329e-03,\n                       -2.0018e-01, -8.8625e-02,  2.5688e-01, -3.7694e-01, -7.9015e-02,\n                        1.1588e-01, -1.8639e-01, -1.6857e-03,  2.3082e-01, -7.0298e-02,\n                        2.0512e-01,  2.2079e-01,  2.7299e-02,  1.1167e-01,  2.8339e-01,\n                        9.3236e-02,  3.1116e-01,  8.4315e-02, -5.2062e-02],\n                      [-2.0319e-01, -2.0266e-02,  2.5910e-01, -2.3579e-01, -9.1621e-02,\n                        7.5453e-02,  1.3930e-01, -1.5459e-02, -2.9669e-01, -1.5096e-01,\n                       -1.0390e-01,  1.4850e-01, -2.3530e-01,  6.2539e-02,  9.6012e-02,\n                        1.0213e-01, -1.5112e-01, -1.6021e-02,  1.2297e-01,  3.5444e-01,\n                        7.5206e-02, -8.7439e-03, -4.9628e-02,  2.2729e-01,  9.9016e-02,\n                       -7.7554e-02,  1.7385e-01, -3.5822e-02, -4.4649e-02,  6.7531e-02,\n                        1.2300e-01, -3.3263e-01, -2.3843e-01, -2.4618e-01,  1.6303e-01,\n                        1.6365e-01, -2.1908e-01, -1.1081e-01,  3.2164e-01,  5.4476e-02,\n                        7.0932e-02,  1.2309e-01,  2.3735e-01,  1.2163e-01, -1.2070e-01,\n                        2.7517e-01, -1.2827e-01, -1.3709e-01,  2.3435e-01,  9.1282e-02,\n                       -2.1766e-02, -1.0955e-01,  7.4867e-02, -3.2816e-01, -1.3420e-01,\n                        2.4745e-01, -4.2067e-02,  2.1373e-01, -1.6670e-01, -3.6833e-01,\n                        1.5481e-01, -8.3968e-03,  4.3230e-02, -1.2055e-01,  1.0455e-01,\n                        1.8173e-01, -1.3961e-01, -1.6753e-01,  1.4330e-01,  9.4092e-02,\n                       -2.6628e-02, -4.2539e-02, -1.9630e-01,  1.2827e-01, -1.1918e-01,\n                        6.4594e-02,  1.3311e-01,  4.7238e-02, -1.9581e-01,  2.3720e-01,\n                       -1.0158e-01,  2.3019e-01,  2.2761e-01, -8.6859e-02],\n                      [-4.1351e-01, -1.5024e-02, -2.6890e-01,  3.8309e-02,  5.7322e-02,\n                       -8.4521e-02,  9.3860e-02, -1.2649e-01,  1.4652e-01, -2.1303e-01,\n                       -1.2507e-01, -9.8671e-02,  3.7019e-02,  1.2490e-01, -2.3455e-01,\n                        2.5850e-01,  7.1906e-02,  2.2518e-01,  1.0609e-01, -2.5638e-01,\n                        6.6289e-02, -7.9985e-03, -6.9625e-02,  6.0446e-02, -2.5817e-02,\n                        1.1419e-01,  7.9006e-02, -1.9429e-01,  3.5262e-02, -4.4587e-02,\n                        9.0529e-03, -5.2422e-02, -1.6460e-01,  2.2572e-02, -4.5638e-02,\n                       -1.1993e-01, -5.0960e-01, -2.5270e-01,  4.1124e-02,  1.1629e-01,\n                        7.4692e-03,  5.3727e-02, -6.1002e-02,  8.9862e-02, -2.8762e-01,\n                       -2.2898e-01, -1.9447e-01, -6.9326e-02, -1.6721e-01, -1.9865e-01,\n                        1.9295e-02, -2.7013e-02,  5.9335e-02,  8.9467e-02, -4.8294e-02,\n                        2.1737e-02,  8.5396e-02,  1.1085e-01, -6.3693e-02, -1.7252e-02,\n                        3.1844e-02, -2.2090e-01, -2.0433e-01,  3.8573e-02,  6.8020e-02,\n                       -2.0949e-01,  1.2926e-01,  7.2930e-02, -1.9398e-01,  7.0606e-02,\n                        5.2786e-02,  1.9740e-02, -1.6066e-02,  1.4767e-01,  6.9443e-02,\n                        9.0968e-02,  1.0351e-01,  2.2810e-01,  4.3143e-01,  9.0349e-03,\n                        7.5912e-02, -2.3705e-01, -1.0570e-03,  1.3581e-01],\n                      [-2.4049e-01, -1.9382e-02,  3.4299e-02,  4.9441e-02, -1.8726e-01,\n                        7.8071e-02, -1.3150e-01,  1.9577e-01,  3.2465e-02, -5.1338e-02,\n                        1.4994e-01,  1.6585e-01, -1.8762e-01, -1.8436e-01, -1.3562e-01,\n                        1.0603e-01,  2.3895e-01,  7.5376e-02,  4.6856e-02, -1.6475e-02,\n                       -1.0974e-01,  1.3716e-02,  3.5830e-03,  5.5514e-02, -2.1862e-01,\n                       -4.1040e-02, -1.5525e-01, -2.8672e-02,  1.1813e-01, -5.8775e-04,\n                       -6.2096e-02,  5.0898e-02,  1.8739e-01, -6.9351e-02,  1.5233e-01,\n                       -1.5468e-01,  7.0757e-02, -1.3789e-02,  2.4131e-01,  2.6446e-02,\n                        8.0968e-02, -5.6107e-02,  2.9988e-02,  6.8721e-02, -3.4250e-02,\n                       -1.9332e-01,  1.5971e-01, -9.2553e-02, -1.2655e-01, -3.4788e-02,\n                       -1.1077e-01, -2.0592e-01,  1.3947e-01,  1.8543e-01, -3.5590e-02,\n                        1.3842e-01,  1.3764e-01,  9.7723e-02, -2.8806e-01,  1.2320e-02,\n                       -4.2010e-01, -1.2606e-01,  1.1769e-01,  2.0468e-01,  5.1158e-02,\n                       -5.7737e-02, -8.9575e-02,  1.7285e-03,  1.1753e-01, -1.1502e-01,\n                       -1.2191e-01,  2.5013e-01, -7.3065e-02, -1.0823e-01, -1.5701e-01,\n                       -1.0449e-02, -9.8494e-02,  8.5300e-02, -1.4018e-01,  3.5062e-02,\n                       -8.0692e-02,  9.3120e-03, -6.8067e-02,  5.5309e-02],\n                      [-2.2823e-01,  3.9661e-03,  8.1437e-02, -1.2796e-01,  7.7689e-02,\n                       -6.2256e-02, -1.1803e-01, -2.4552e-01, -1.3833e-02, -1.4376e-01,\n                        6.4938e-02,  3.3417e-01, -1.2335e-01, -6.4400e-02, -2.6086e-01,\n                        5.7080e-02,  2.6206e-02, -3.0676e-02, -1.9734e-01, -2.3105e-01,\n                        1.6290e-01, -4.8084e-01,  1.7319e-01,  1.0113e-01,  6.8710e-02,\n                       -9.3935e-02,  2.7229e-02, -1.3492e-01, -9.1820e-02,  4.2777e-02,\n                        6.5144e-02,  2.8735e-02,  1.9840e-01, -3.1073e-01, -1.1407e-01,\n                       -1.7465e-01,  2.0618e-01,  1.0955e-01, -1.3846e-01, -5.0310e-03,\n                        4.9019e-01, -3.1194e-02,  6.1298e-02,  2.5802e-01, -3.2536e-02,\n                       -1.0196e-01, -1.8565e-01,  3.1201e-02, -1.4772e-01, -4.3677e-02,\n                        2.9583e-01,  2.8519e-01,  4.9889e-02,  1.7137e-01,  2.5663e-01,\n                       -1.7145e-01, -1.9142e-01,  2.0388e-01, -1.6107e-01, -2.3219e-01,\n                       -2.0942e-01,  5.5833e-02, -5.2661e-03, -1.5407e-01,  4.8261e-02,\n                        5.9500e-02, -4.9015e-02,  6.0974e-03, -4.2011e-02,  8.1983e-02,\n                        5.4278e-02, -1.2280e-01, -9.8326e-02,  1.6229e-01,  3.0204e-01,\n                       -1.2740e-01, -7.2775e-02,  1.3889e-01,  1.7331e-01, -2.2350e-01,\n                       -6.1832e-02, -1.1697e-01, -9.3655e-02, -1.5971e-01]],\n                     grad_fn=<ViewBackward0>)),\n             ('fc3.bias',\n              tensor([ 0.1230, -0.0641, -0.2118,  0.2418, -0.2097,  0.3006, -0.1371, -0.1057,\n                      -0.0563,  0.2076], grad_fn=<ViewBackward0>))])"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(weights)\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 128])"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_stat = tran.state_dict()\n",
    "net_stat['encoder.attn_layers.2.attention.out_projection.weight'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.1520, -0.0317, -0.2242,  ..., -0.0435,  0.0419, -0.1446],\n        [ 0.1454, -0.0201, -0.0644,  ...,  0.0057,  0.0147, -0.1237],\n        [-0.1787,  0.1632, -0.0003,  ...,  0.0698,  0.0187, -0.1029],\n        ...,\n        [ 0.0246, -0.0194,  0.0339,  ..., -0.0164, -0.0685,  0.0913],\n        [-0.0593,  0.1192,  0.0149,  ...,  0.0051, -0.2329, -0.0383],\n        [-0.0648, -0.0676,  0.0345,  ..., -0.0263,  0.0120,  0.0586]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnet = ViTHyper(n_nodes=50, embedding_dim=10, hidden_dim=128, dim=128, client_sample=1, depth=3)\n",
    "tran = Transformer(enc_in=33, c_out=33)\n",
    "input = torch.rand((128, 12, 33))\n",
    "output, attns = tran(input)\n",
    "weights = hnet(torch.tensor([node_id], dtype=torch.long),False)\n",
    "weights[0]['transformer.layers.0.0.fn.to_qkv.weight']\n",
    "# print(hnet, tran)\n",
    "# for param_tensor in hnet.state_dict():\n",
    "#     print(param_tensor, \"\\t\", hnet.state_dict()[param_tensor].size())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranformer_stat = tran.state_dict()\n",
    "tranformer_stat['encoder.attn_layers.0.attention.query_projection.weight'] = weights[0]['transformer.layers.0.0.fn.to_qkv.weight']\n",
    "tran.load_state_dict(tranformer_stat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partition_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [155], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts \u001B[38;5;241m=\u001B[39m \u001B[43mpartition_data\u001B[49m(\n\u001B[0;32m      2\u001B[0m         dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpsm\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      3\u001B[0m         datadir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      4\u001B[0m         partition \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnoniid\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      5\u001B[0m         n_parties \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m      6\u001B[0m     )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'partition_data' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts = partition_data(\n",
    "        dataset = 'psm',\n",
    "        datadir = \"../data\",\n",
    "        partition = \"noniid\",\n",
    "        n_parties = 10\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hjf\\.matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "print(mpl.get_cachedir())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'hjf')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 3600x1200 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.style.use(['science', 'ieee'])\n",
    "# plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams['figure.figsize'] = 6, 2\n",
    "plt.figure()\n",
    "plt.title(\"hjf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arial\n",
      "Arial\n",
      "Arial\n",
      "Arial\n",
      "Arial\n",
      "Bahnschrift\n",
      "Calibri\n",
      "Calibri\n",
      "Calibri\n",
      "Calibri\n",
      "Calibri\n",
      "Calibri\n",
      "Cambria\n",
      "Cambria\n",
      "Cambria\n",
      "Cambria\n",
      "Candara\n",
      "Candara\n",
      "Candara\n",
      "Candara\n",
      "Candara\n",
      "Candara\n",
      "Comic Sans MS\n",
      "Comic Sans MS\n",
      "Comic Sans MS\n",
      "Comic Sans MS\n",
      "Consolas\n",
      "Consolas\n",
      "Consolas\n",
      "Consolas\n",
      "Constantia\n",
      "Constantia\n",
      "Constantia\n",
      "Constantia\n",
      "Corbel\n",
      "Corbel\n",
      "Corbel\n",
      "Corbel\n",
      "Corbel\n",
      "Corbel\n",
      "Courier New\n",
      "Courier New\n",
      "Courier New\n",
      "Courier New\n",
      "DejaVu Sans\n",
      "DejaVu Sans\n",
      "DejaVu Sans\n",
      "DejaVu Sans\n",
      "DejaVu Sans Display\n",
      "DejaVu Sans Mono\n",
      "DejaVu Sans Mono\n",
      "DejaVu Sans Mono\n",
      "DejaVu Sans Mono\n",
      "DejaVu Serif\n",
      "DejaVu Serif\n",
      "DejaVu Serif\n",
      "DejaVu Serif\n",
      "DejaVu Serif Display\n",
      "DengXian\n",
      "DengXian\n",
      "DengXian\n",
      "Ebrima\n",
      "Ebrima\n",
      "FangSong\n",
      "Franklin Gothic Medium\n",
      "Franklin Gothic Medium\n",
      "Gabriola\n",
      "Gadugi\n",
      "Gadugi\n",
      "Georgia\n",
      "Georgia\n",
      "Georgia\n",
      "Georgia\n",
      "HoloLens MDL2 Assets\n",
      "Impact\n",
      "Ink Free\n",
      "Javanese Text\n",
      "KaiTi\n",
      "Leelawadee UI\n",
      "Leelawadee UI\n",
      "Leelawadee UI\n",
      "Lucida Console\n",
      "Lucida Sans Unicode\n",
      "MS Gothic\n",
      "MV Boli\n",
      "Malgun Gothic\n",
      "Malgun Gothic\n",
      "Malgun Gothic\n",
      "Marlett\n",
      "Microsoft Himalaya\n",
      "Microsoft JhengHei\n",
      "Microsoft JhengHei\n",
      "Microsoft JhengHei\n",
      "Microsoft New Tai Lue\n",
      "Microsoft New Tai Lue\n",
      "Microsoft PhagsPa\n",
      "Microsoft PhagsPa\n",
      "Microsoft Sans Serif\n",
      "Microsoft Tai Le\n",
      "Microsoft Tai Le\n",
      "Microsoft YaHei\n",
      "Microsoft YaHei\n",
      "Microsoft YaHei\n",
      "Microsoft Yi Baiti\n",
      "MingLiU-ExtB\n",
      "Mongolian Baiti\n",
      "Myanmar Text\n",
      "Myanmar Text\n",
      "Nirmala UI\n",
      "Nirmala UI\n",
      "Nirmala UI\n",
      "Palatino Linotype\n",
      "Palatino Linotype\n",
      "Palatino Linotype\n",
      "Palatino Linotype\n",
      "STIXGeneral\n",
      "STIXGeneral\n",
      "STIXGeneral\n",
      "STIXGeneral\n",
      "STIXNonUnicode\n",
      "STIXNonUnicode\n",
      "STIXNonUnicode\n",
      "STIXNonUnicode\n",
      "STIXSizeFiveSym\n",
      "STIXSizeFourSym\n",
      "STIXSizeFourSym\n",
      "STIXSizeOneSym\n",
      "STIXSizeOneSym\n",
      "STIXSizeThreeSym\n",
      "STIXSizeThreeSym\n",
      "STIXSizeTwoSym\n",
      "STIXSizeTwoSym\n",
      "Segoe MDL2 Assets\n",
      "Segoe Print\n",
      "Segoe Print\n",
      "Segoe Script\n",
      "Segoe Script\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI\n",
      "Segoe UI Emoji\n",
      "Segoe UI Historic\n",
      "Segoe UI Symbol\n",
      "SimHei\n",
      "SimSun\n",
      "SimSun-ExtB\n",
      "Sitka Small\n",
      "Sitka Small\n",
      "Sitka Small\n",
      "Sitka Small\n",
      "Sylfaen\n",
      "Symbol\n",
      "Tahoma\n",
      "Tahoma\n",
      "Times New Roman\n",
      "Times New Roman\n",
      "Times New Roman\n",
      "Times New Roman\n",
      "Trebuchet MS\n",
      "Trebuchet MS\n",
      "Trebuchet MS\n",
      "Trebuchet MS\n",
      "Verdana\n",
      "Verdana\n",
      "Verdana\n",
      "Verdana\n",
      "Webdings\n",
      "Wingdings\n",
      "Yu Gothic\n",
      "Yu Gothic\n",
      "Yu Gothic\n",
      "Yu Gothic\n",
      "cmb10\n",
      "cmex10\n",
      "cmmi10\n",
      "cmr10\n",
      "cmss10\n",
      "cmsy10\n",
      "cmtt10\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import font_manager\n",
    "\n",
    "font_list=sorted([f.name for f in matplotlib.font_manager.fontManager.ttflist])\n",
    "for i in font_list:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
